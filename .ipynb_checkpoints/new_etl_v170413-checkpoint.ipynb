{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import io\n",
    "import csv\n",
    "import shutil\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "import mysql.connector as sql\n",
    "from sqlalchemy import create_engine\n",
    "from mysql.connector import MySQLConnection, Error\n",
    "default_stdout = sys.stdout\n",
    "default_stderr = sys.stderr\n",
    "reload(sys)\n",
    "sys.stdout = default_stdout\n",
    "sys.stderr = default_stderr\n",
    "sys.setdefaultencoding('utf-8')\n",
    "\n",
    "except_txt_path = '/Users/Jackie/Desktop/except_txt/'\n",
    "err_path = '/Users/Jackie/Desktop/error'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIKPW00 有字串在位置，已清好\n",
      "資料重複拉！笨蛋 EVEZPT20\n",
      "資料重複拉！笨蛋 EVHJS620\n",
      "資料重複拉！笨蛋 EVHKQP20\n",
      "資料重複拉！笨蛋 EVI9R760\n",
      "資料重複拉！笨蛋 EVIWR760\n",
      "資料重複拉！笨蛋 EVJES820\n",
      "資料重複拉！笨蛋 EVJFQQ60\n",
      "資料重複拉！笨蛋 EVKESJ10\n",
      "資料重複拉！笨蛋 EVKXRL60\n",
      "資料重複拉！笨蛋 EVL6RM20\n",
      "資料重複拉！笨蛋 EVL7TM20\n",
      "資料重複拉！笨蛋 EVLDTB20\n",
      "資料重複拉！笨蛋 NVHEPV40\n",
      "資料重複拉！笨蛋 NVIKPW00\n",
      "資料重複拉！笨蛋 NVIVS602\n",
      "資料重複拉！笨蛋 NVIWRJ00\n",
      "資料重複拉！笨蛋 NVJERC00\n",
      "資料重複拉！笨蛋 NVJFPW01\n",
      "資料重複拉！笨蛋 NVJFQQ00\n",
      "資料重複拉！笨蛋 PV0160C0\n",
      "資料重複拉！笨蛋 PV0380F0\n",
      "資料重複拉！笨蛋 PV0390G0\n",
      "資料重複拉！笨蛋 PV03A0G0\n",
      "資料重複拉！笨蛋 PV6380E0\n",
      "資料重複拉！笨蛋 PV7010A0\n",
      "資料重複拉！笨蛋 PV9030A2\n",
      "資料重複拉！笨蛋 PV9040A0\n",
      "資料重複拉！笨蛋 PV9050A0\n",
      "資料重複拉！笨蛋 PV9060A0\n",
      "資料重複拉！笨蛋 PV9201A0\n",
      "資料重複拉！笨蛋 PV9211A0\n",
      "資料重複拉！笨蛋 PV9230A1\n",
      "資料重複拉！笨蛋 PV9240A0\n",
      "資料重複拉！笨蛋 PV9250A2\n",
      "資料重複拉！笨蛋 PVGYS640\n",
      "資料重複拉！笨蛋 PVGYS7A0\n",
      "資料重複拉！笨蛋 PVHEPV00\n",
      "資料重複拉！笨蛋 PVHXS600\n",
      "資料重複拉！笨蛋 PVI9QP10\n",
      "資料重複拉！笨蛋 PVI9QP11\n",
      "資料重複拉！笨蛋 PVI9RW20\n",
      "資料重複拉！笨蛋 PVI9S600\n",
      "資料重複拉！笨蛋 PVIKQP20\n",
      "資料重複拉！笨蛋 PVIKQU50\n",
      "資料重複拉！笨蛋 PVIWRJ60\n",
      "資料重複拉！笨蛋 PVJDST20\n",
      "資料重複拉！笨蛋 PVJERC50\n",
      "資料重複拉！笨蛋 PVJERC51\n",
      "資料重複拉！笨蛋 PVJERC52\n",
      "資料重複拉！笨蛋 PVJFPW00\n",
      "資料重複拉！笨蛋 PVJVRL10\n",
      "資料重複拉！笨蛋 PVJVRL11\n",
      "資料重複拉！笨蛋 QVIKQP20\n",
      "資料重複拉！笨蛋 SVIVS602\n",
      "資料重複拉！笨蛋 SVIWRJ00\n",
      "資料重複拉！笨蛋 SVJERC40\n",
      "資料重複拉！笨蛋 SVJFPW01\n",
      "資料重複拉！笨蛋 SVJFQQ00\n",
      "資料重複拉！笨蛋 UVGYS7A1\n",
      "資料重複拉！笨蛋 UVHKPV40\n",
      "資料重複拉！笨蛋 UVJVRL40\n",
      "資料重複拉！笨蛋 WVEUPN60\n",
      "資料重複拉！笨蛋 WVHJS620\n",
      "資料重複拉！笨蛋 WVHKQP20\n",
      "資料重複拉！笨蛋 WVI9R760\n",
      "資料重複拉！笨蛋 WVIKPW61\n",
      "資料重複拉！笨蛋 WVIWR760\n",
      "資料重複拉！笨蛋 WVJCTT60\n",
      "資料重複拉！笨蛋 WVJES820\n",
      "資料重複拉！笨蛋 WVJFQQ60\n",
      "資料重複拉！笨蛋 WVK6NY60\n",
      "資料重複拉！笨蛋 WVKESJ10\n",
      "資料重複拉！笨蛋 WVL6RM20\n",
      "資料重複拉！笨蛋 WVLDTB20\n"
     ]
    }
   ],
   "source": [
    "def new_checkandinsert(insert_path,except_txt_path,err_path):\n",
    "    try:\n",
    "        import os\n",
    "        ct=time.strftime('%Y%m%d',time.localtime())\n",
    "        \"\"\"\n",
    "\n",
    "        主要是使用連結資料庫的第三方套件mysql.connector，\n",
    "        以python去對資料庫做連結，在利用for loop把資料insert到正確的table下。\n",
    "        161110改正，要在insert前做檢查日期及時間\n",
    "        170413 更新 使用pandas\n",
    "        \"\"\"\n",
    "        def decode_to_utf8(df):\n",
    "        #     df.EQIPnumber=df.EQIPnumber.str.decode(\"utf-8\")\n",
    "        #     df.location=df.location.str.decode(\"utf-8\")\n",
    "        #     df.direct=df.direct.str.decode(\"utf-8\")\n",
    "            df.YMD=df.YMD.str.decode(\"utf-8\")\n",
    "            df.hour=df.hour.str.decode(\"utf-8\")\n",
    "            return df\n",
    "\n",
    "        db_connection = sql.connect(host='localhost', database='new_etl', user='root', password='apple')\n",
    "        new_etl = create_engine('mysql+mysqlconnector://root:apple@localhost:3306/new_etl', echo=False)\n",
    "\n",
    "        files = []\n",
    "        for f in os.listdir(insert_path):\n",
    "            if os.path.isfile(insert_path + f) & ('.csv' in f):\n",
    "                files.append(f)\n",
    "\n",
    "        '''把DB的tablename通通抓出來'''\n",
    "        redirect_list=pd.read_sql('show tables;', con = db_connection)\n",
    "        db_list=redirect_list.ix[:,0].tolist()\n",
    "        for f in files:\n",
    "            # 在這裡判斷有沒有存在DB中\n",
    "            match = re.findall('[A-Z0-9]+', f)\n",
    "            matchname = str(match[0])\n",
    "            if matchname in db_list:\n",
    "                db_time = pd.read_sql('select YMD,hour from {};'.format(matchname), con = db_connection)\n",
    "                db_time = decode_to_utf8(db_time)\n",
    "                tempf = pd.read_csv(insert_path + f)\n",
    "                if pd.merge(db_time,tempf,on =[\"YMD\",\"hour\"]).empty:\n",
    "                    qdf.to_sql(name = matchname,con=new_etl , if_exists='append',index = False)\n",
    "                else:\n",
    "                    print u'資料重複拉！笨蛋',matchname\n",
    "                    if not os.path.exists(err_path+ct+'repeat'):\n",
    "                        os.makedirs(err_path+ct+'repeat')\n",
    "                    shutil.move(insert_path+f ,err_path+ct+'repeat/'+f)\n",
    "                    continue\n",
    "            else:\n",
    "                print matchname, \"not in DataBase\"\n",
    "                if not os.path.exists(err_path+ct+'notinDB'):\n",
    "                    os.makedirs(err_path+ct+'notinDB')\n",
    "                shutil.move(insert_path+f ,err_path+ct+'notinDB/'+f)\n",
    "                continue\n",
    "    except:\n",
    "        if not os.path.exists(except_txt_path):\n",
    "            os.makedirs(except_txt_path)\n",
    "        with open(except_txt_path+'insert_err.txt','w') as here3:\n",
    "            here3.write(u'insert exception'+u'\\n')\n",
    "            here3.write(str(sys.stderr)+u'\\n')\n",
    "            here3.write(str(sys.exc_info()[0])+u'\\n')\n",
    "            here3.write(str(sys.exc_info()[1])+u'\\n')\n",
    "            here3.write(str(sys.exc_info()[2])+u'\\n')\n",
    "\n",
    "def new_etl_v170413(f,filepath,except_txt_path):\n",
    "    try:\n",
    "        t=pd.read_csv(f,sep=',,',header=1,skipfooter=2,engine='python').dropna(axis=(0,1),how =\"all\")\n",
    "        t=t.reset_index(drop=True)\n",
    "        tc = t.copy()\n",
    "        cols=[\"EQIPnumber\",\"location\",\"direct\",\"YMD\",\"hour\",\"laneNumber\",\"addTotal\",\"15Total\"\\\n",
    "         ,\"truckflow\",\"carflow\",\"scooterflow\",\"avgspeed\",\"avgPercent\",\"avgCarSpace\"]\n",
    "\n",
    "        vdlist = tc.ix[:,0].unique().tolist()\n",
    "        for table in vdlist:\n",
    "            temp = tc.ix[tc.ix[:,0] == table].reset_index(drop=True)\n",
    "            if ',' in temp.ix[0,1]:\n",
    "                temp.ix[:,1]=temp.ix[:,1].str.replace(',','').str.strip('\"').copy()\n",
    "                print table,\"有字串在位置，已清好\"\n",
    "            # 把日期跟時間分開再插入原來的table\n",
    "            tempc=temp.copy()\n",
    "            split = tempc.ix[:,3].str.split(\" \", expand=True).copy()\n",
    "            tempc.insert(3,'date',split[0])\n",
    "            tempc.ix[:,4] = split[1]\n",
    "            temp = tempc\n",
    "            # if temp資料夾不存在就生成 \n",
    "            if not os.path.exists(filepath):\n",
    "                os.makedirs(filepath)\n",
    "            Sdf = temp.ix[temp.ix[:,2].str.contains(r'南')]\n",
    "            Ndf = temp.ix[temp.ix[:,2].str.contains(r'北')]\n",
    "            Edf = temp.ix[temp.ix[:,2].str.contains(r'東')]\n",
    "            Wdf = temp.ix[temp.ix[:,2].str.contains(r'西')]\n",
    "            Pdf = temp.ix[temp.ix[:,2].str.contains(r'正')]\n",
    "            Udf = temp.ix[temp.ix[:,2].str.contains(r'未')]\n",
    "            Qdf = temp.ix[temp.ix[:,2].str.contains(r'[反負]向')]\n",
    "            directdict = {\"S\":Sdf,\"N\":Ndf,\"E\":Edf,\"W\":Wdf,\"P\":Pdf,\"U\":Udf,\"Q\":Qdf}\n",
    "            for direct in directdict:\n",
    "                if directdict[direct].empty:\n",
    "                    pass\n",
    "                else:\n",
    "                    fullpath = filepath+direct+temp.ix[:,0].unique()[0]\n",
    "                    directdict[direct].to_csv(fullpath+'.csv',index=False,header = cols)\n",
    "    except:\n",
    "        if not os.path.exists(except_txt_path):\n",
    "            os.makedirs(except_txt_path)\n",
    "        with open(except_txt_path+'ETL.txt','w') as here3:\n",
    "            here3.write(u'ETL exception'+u'\\n')\n",
    "            here3.write(str(sys.stderr)+u'\\n')\n",
    "            here3.write(str(sys.exc_info()[0])+u'\\n')\n",
    "            here3.write(str(sys.exc_info()[1])+u'\\n')\n",
    "            here3.write(str(sys.exc_info()[2])+u'\\n')     \n",
    "f ='/Users/Jackie/Desktop/test_xshin.csv'\n",
    "insert_path = '/Users/Jackie/Desktop/temp/'\n",
    "new_etl_v170413(f,insert_path,except_txt_path)\n",
    "new_checkandinsert(insert_path,except_txt_path,err_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
